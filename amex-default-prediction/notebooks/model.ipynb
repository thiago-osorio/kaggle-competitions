{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import skopt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('customer_ID').tail(1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(train_label, how='left', left_on='customer_ID', right_on='customer_ID')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns = ['customer_ID', 'S_2', 'S_3','D_42','D_43','D_46','D_49','D_50','D_53','S_7','D_56','S_9','B_17','D_66','D_73','D_76','D_77','R_9','D_82','B_29','D_87','D_88','D_105','D_106','R_26','D_108','D_110','D_111','B_39','S_27','B_42','D_132','D_134','D_135','D_136','D_137','D_138','D_142']\n",
    "df.drop(useless_columns, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_68']\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = ['P_2','D_39','B_1','B_2','R_1','D_41','B_3','D_44','B_4','D_45','B_5','R_2','D_47','D_48','B_6','B_7','B_8','D_51','B_9','R_3','D_52','P_3','B_10','S_5','B_11','S_6','D_54','R_4','B_12','S_8','D_55','B_13','R_5','D_58','B_14','D_59','D_60','D_61','B_15','S_11','D_62','D_65','B_16','B_18','B_19','B_20','S_12','R_6','S_13','B_21','D_69','B_22','D_70','D_71','D_72','S_15','B_23','P_4','D_74','D_75','B_24','R_7','B_25','B_26','D_78','D_79','R_8','S_16','D_80','R_10','R_11','B_27','D_81','S_17','R_12','B_28','R_13','D_83','R_14','R_15','D_84','R_16','S_18','D_86','R_17','R_18','B_31','S_19','R_19','B_32','S_20','R_20','R_21','B_33','D_89','R_22','R_23','D_91','D_92','D_93','D_94','R_24','R_25','D_96','S_22','S_23','S_24','S_25','S_26','D_102','D_103','D_104','D_107','B_36','B_37','R_27','D_109','D_112','B_40','D_113','D_115','D_118','D_119','D_121','D_122','D_123','D_124','D_125','D_127','D_128','D_129','B_41','D_130','D_131','D_133','R_28','D_139','D_140','D_141','D_143','D_144','D_145']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(estimator=LinearRegression(), max_iter=30, imputation_order='roman')),\n",
    "    ('pca', PCA(n_components=20))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('cat', cat_transformer, cat_data),\n",
    "    ('num', numeric_transformer, numeric_data)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "    print(\"G: {:.6f}, D: {:.6f}, ALL: {:6f}\".format(gini[1]/gini[0], top_four, 0.5*(gini[1]/gini[0] + top_four)))\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.make_scorer(amex_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [RandomForestClassifier(class_weight='balanced'), LogisticRegression(class_weight='balanced'), LGBMClassifier(class_weight='balanced'), CatBoostClassifier(class_weights=class_weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelo in modelos:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor', transformer),\n",
    "        ('model', modelo)\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=skf, scoring=metric)\n",
    "    print(f'''\n",
    "          Modelo: {modelo} CV AMEX Score: {scores.mean()*100} +/- {scores.std()*100}%'\n",
    "          ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21092cf6c725eea58795aaae078f12755daaaf957912a2c5aa09910e58ee6873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
